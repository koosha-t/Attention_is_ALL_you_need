# Transformer

Transformer is the first transduction model relying entirely on 
self-attention to compute representations of its input and output
without using sequence aligned RNNs or convolution.



